{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff1787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be07e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-c CONFIG] [-m MODE]\n",
      "                             [-o {2d_sparse,2d_dense,3d}] [-n_pre N_PRE]\n",
      "                             [-n_next N_NEXT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/run/user/1000/jupyter/runtime/kernel-v3ea7f88d545ecf2c46bb08dde45663296a5038e2c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryan_santosa/conda_envs/deeplearning/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import yaml\n",
    "import torch\n",
    "import mediapipe as mp\n",
    "from models.expression_head import ExpressionHead\n",
    "from FaceBoxes import FaceBoxes\n",
    "from TDDFA import TDDFA\n",
    "from utils.render import render\n",
    "from utils.functions import cv_draw_landmark\n",
    "\n",
    "def extract_mp_landmarks(img, mp_face):\n",
    "    h, w, _ = img.shape\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    res = mp_face.process(rgb)\n",
    "\n",
    "    if not res.multi_face_landmarks:\n",
    "        return None\n",
    "\n",
    "    lm = res.multi_face_landmarks[0].landmark\n",
    "    pts = np.array([[p.x * w, p.y * h, p.z] for p in lm])\n",
    "    return pts.reshape(-1)\n",
    "\n",
    "def draw_expression_text(img, expr, title, x, y):\n",
    "    if expr is None:\n",
    "        return\n",
    "\n",
    "    cv2.putText(img, title, (x, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n",
    "\n",
    "    for i, v in enumerate(expr):\n",
    "        cv2.putText(img, f\"{i}: {v:.2f}\", (x, y + 15*(i+1)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    cfg = yaml.load(open(args.config), Loader=yaml.SafeLoader)\n",
    "\n",
    "    # init\n",
    "    gpu_mode = args.mode == 'gpu'\n",
    "    tddfa = TDDFA(gpu_mode=gpu_mode, **cfg)\n",
    "    # -------- Expression Head --------\n",
    "    expr_model = ExpressionHead()\n",
    "    expr_model.load_state_dict(\n",
    "        torch.load(\"expression_head.pth\", map_location=\"cpu\")\n",
    "    )\n",
    "    expr_model.eval()\n",
    "\n",
    "    # -------- MediaPipe --------\n",
    "    mp_face = mp.solutions.face_mesh.FaceMesh(\n",
    "        static_image_mode=False,\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True\n",
    "    )\n",
    "\n",
    "    face_boxes = FaceBoxes()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    n_pre, n_next = args.n_pre, args.n_next\n",
    "    n = n_pre + n_next + 1\n",
    "\n",
    "    queue_ver = deque()\n",
    "    queue_frame = deque()\n",
    "\n",
    "    dense_flag = args.opt in ('2d_dense', '3d')\n",
    "    pre_ver = None\n",
    "    first_frame = True\n",
    "\n",
    "    while True:\n",
    "        lm = extract_mp_landmarks(img, mp_face)\n",
    "        expr_ours = None\n",
    "\n",
    "        if lm is not None:\n",
    "            with torch.no_grad():\n",
    "                lm_t = torch.from_numpy(lm).float().unsqueeze(0)\n",
    "                expr_ours = expr_model(lm_t).numpy()[0]\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img = frame.copy()\n",
    "\n",
    "        if first_frame:\n",
    "            boxes = face_boxes(img)\n",
    "            if len(boxes) == 0:\n",
    "                draw_expression_text(out, expr_3ddfa, \"3DDFA Expr\", 10, 20)\n",
    "                draw_expression_text(out, expr_ours, \"Ours (2D LM)\", 200, 20)\n",
    "                cv2.imshow(\"image\", img)\n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            boxes = [boxes[0]]\n",
    "            param_lst, roi_box_lst = tddfa(img, boxes)\n",
    "            expr_3ddfa = param_lst[0][12:22]  # 10-dim expression\n",
    "            ver = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)[0]\n",
    "\n",
    "            # padding queue\n",
    "            for _ in range(n_pre):\n",
    "                queue_ver.append(ver.copy())\n",
    "                queue_frame.append(img.copy())\n",
    "\n",
    "            queue_ver.append(ver.copy())\n",
    "            queue_frame.append(img.copy())\n",
    "\n",
    "            pre_ver = ver.copy()\n",
    "            first_frame = False\n",
    "\n",
    "        else:\n",
    "            param_lst, roi_box_lst = tddfa(img, [pre_ver], crop_policy='landmark')\n",
    "            ver = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)[0]\n",
    "\n",
    "            queue_ver.append(ver.copy())\n",
    "            queue_frame.append(img.copy())\n",
    "\n",
    "            pre_ver = ver.copy()\n",
    "\n",
    "        # ---- smoothing & rendering ----\n",
    "        if len(queue_ver) >= n:\n",
    "            ver_ave = np.mean(queue_ver, axis=0)\n",
    "            base_frame = queue_frame[n_pre]  # FIX: always exists\n",
    "\n",
    "            if args.opt == '2d_sparse':\n",
    "                out = cv_draw_landmark(base_frame, ver_ave)\n",
    "            elif args.opt == '2d_dense':\n",
    "                out = cv_draw_landmark(base_frame, ver_ave, size=1)\n",
    "            elif args.opt == '3d':\n",
    "                out = render(base_frame, [ver_ave], tddfa.tri, alpha=0.7)\n",
    "\n",
    "            cv2.imshow(\"image\", out)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "            queue_ver.popleft()\n",
    "            queue_frame.popleft()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-c', '--config', default='configs/mb1_120x120.yml')\n",
    "    parser.add_argument('-m', '--mode', default='cpu')\n",
    "    parser.add_argument('-o', '--opt', default='3d',\n",
    "                        choices=['2d_sparse', '2d_dense', '3d'])\n",
    "    parser.add_argument('-n_pre', default=1, type=int)\n",
    "    parser.add_argument('-n_next', default=1, type=int)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
